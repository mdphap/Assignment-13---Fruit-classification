{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fruits_name = [name for name in os.listdir(r'D:\\Machine Learning 3\\fruits-360\\Training')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make an empty list to store training image and label\n",
    "trainData = []\n",
    "trainLabels = []\n",
    "\n",
    "# loop through images in training folder, read image and append to dataframe\n",
    "for name in fruits_name:\n",
    "    folder_path = r'D:\\Machine Learning 3\\fruits-360\\Training\\\\' + name + '\\\\'\n",
    "    glob_path = glob.glob(folder_path + '*.jpg')\n",
    "    for im_path in glob_path:\n",
    "        im_tempo = cv2.imread(im_path)\n",
    "        trainData.append(im_tempo)\n",
    "        trainLabels.append(name)\n",
    "trainData = np.array(trainData)\n",
    "trainLabels = np.array(trainLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41322, 100, 100, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make an empty list to store test image and label\n",
    "testData = []\n",
    "testLabels = []\n",
    "\n",
    "# loop through images in test folder, read image and append to dataframe\n",
    "for name in fruits_name:\n",
    "    folder_path = r'D:\\Machine Learning 3\\fruits-360\\Test\\\\' + name + '\\\\'\n",
    "    glob_path = glob.glob(folder_path + '*.jpg')\n",
    "    for im_path in glob_path:\n",
    "        im_tempo = cv2.imread(im_path)\n",
    "        testData.append(im_tempo)\n",
    "        testLabels.append(name)\n",
    "testData = np.array(testData)\n",
    "testLabels = np.array(testLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13877, 100, 100, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LeNet import LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale data to [0,1]\n",
    "trainData = trainData.astype('float32')/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# factorize labels and keep a save record for later reference\n",
    "tempo = np.concatenate((trainLabels, testLabels))                          # concatenate labels into one\n",
    "factorize = pd.factorize(tempo)                                            # factorzie labels\n",
    "tempo_category = np_utils.to_categorical(factorize[0], len(fruits_name))   # categorize labels\n",
    "trainLabels = tempo_category[:len(trainLabels)]                            # put categorized labels to data\n",
    "testLabels = tempo_category[len(trainLabels):]                             # put categorized labels to data_test\n",
    "fruit_table = pd.Series(factorize[1])                                      # create table for later references\n",
    "del tempo\n",
    "del tempo_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adagrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer: SGD\n",
    "opt = Adagrad(lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LeNet.build(numChannels=3, imgRows=100, imgCols=100, numClasses=len(fruits_name),\n",
    "                    weightsPath = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 100, 100, 6)       456       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 100, 100, 6)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 50, 50, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 50, 50, 16)        2416      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 50, 50, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 25, 25, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 10000)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               1280128   \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 81)                10449     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 81)                0         \n",
      "=================================================================\n",
      "Total params: 1,293,449\n",
      "Trainable params: 1,293,449\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "41322/41322 [==============================] - 371s 9ms/step - loss: 0.8319 - acc: 0.8028\n",
      "Epoch 2/10\n",
      "41322/41322 [==============================] - 369s 9ms/step - loss: 0.0381 - acc: 0.9921\n",
      "Epoch 3/10\n",
      "41322/41322 [==============================] - 365s 9ms/step - loss: 0.0225 - acc: 0.9943\n",
      "Epoch 4/10\n",
      "41322/41322 [==============================] - 369s 9ms/step - loss: 0.0173 - acc: 0.9947\n",
      "Epoch 5/10\n",
      "41322/41322 [==============================] - 370s 9ms/step - loss: 0.0155 - acc: 0.9947\n",
      "Epoch 6/10\n",
      "41322/41322 [==============================] - 369s 9ms/step - loss: 0.0138 - acc: 0.9947\n",
      "Epoch 7/10\n",
      "41322/41322 [==============================] - 371s 9ms/step - loss: 0.0140 - acc: 0.9944\n",
      "Epoch 8/10\n",
      "41322/41322 [==============================] - 371s 9ms/step - loss: 0.0126 - acc: 0.9945\n",
      "Epoch 9/10\n",
      "41322/41322 [==============================] - 430s 10ms/step - loss: 0.0121 - acc: 0.9950\n",
      "Epoch 10/10\n",
      "41322/41322 [==============================] - 492s 12ms/step - loss: 0.0111 - acc: 0.9952\n"
     ]
    }
   ],
   "source": [
    "model_history = model.fit(trainData, trainLabels, batch_size = 128, epochs = 10, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "model.save_weights(r'D:\\Machine Learning 3\\Assignment fruit\\Benchmark\\Variation\\Tuned\\Adagrad.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save training history\n",
    "import pickle\n",
    "with open(r'D:\\Machine Learning 3\\Assignment fruit\\Benchmark\\Variation\\Tuned\\Adagrad-history', 'wb') as fileop:\n",
    "    pickle.dump(model_history, fileop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete trainData\n",
    "del trainData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale testData to [0,1]\n",
    "testData = testData.astype('float32')/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13877/13877 [==============================] - 84s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "# predict on test dataset\n",
    "predict_label = model.predict(testData, batch_size = 128, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn the predict vector to final predict base on argmax\n",
    "predict_label = [np.argmax(i) for i in predict_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn the test labels vector to final label base on argmax\n",
    "testLabels = [np.argmax(i) for i in testLabels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.74      0.83       164\n",
      "           1       1.00      0.99      1.00       164\n",
      "           2       1.00      1.00      1.00       164\n",
      "           3       0.77      0.98      0.86       161\n",
      "           4       0.98      0.99      0.98       164\n",
      "           5       0.87      0.79      0.83       164\n",
      "           6       1.00      0.96      0.98       164\n",
      "           7       0.81      1.00      0.89       144\n",
      "           8       1.00      1.00      1.00       166\n",
      "           9       1.00      0.89      0.94       164\n",
      "          10       1.00      0.94      0.97       164\n",
      "          11       1.00      1.00      1.00       143\n",
      "          12       1.00      1.00      1.00       166\n",
      "          13       1.00      0.80      0.89       166\n",
      "          14       0.96      0.74      0.84       166\n",
      "          15       0.83      1.00      0.91       166\n",
      "          16       1.00      1.00      1.00       164\n",
      "          17       1.00      0.99      1.00       164\n",
      "          18       1.00      1.00      1.00       166\n",
      "          19       0.63      0.63      0.63       164\n",
      "          20       0.65      0.76      0.70       246\n",
      "          21       1.00      1.00      1.00       246\n",
      "          22       1.00      1.00      1.00       164\n",
      "          23       1.00      1.00      1.00       164\n",
      "          24       1.00      1.00      1.00       164\n",
      "          25       1.00      0.97      0.98       166\n",
      "          26       0.99      0.96      0.98       166\n",
      "          27       1.00      1.00      1.00       166\n",
      "          28       1.00      1.00      1.00       166\n",
      "          29       1.00      1.00      1.00       164\n",
      "          30       1.00      1.00      1.00       166\n",
      "          31       1.00      1.00      1.00       166\n",
      "          32       1.00      1.00      1.00       166\n",
      "          33       1.00      1.00      1.00       164\n",
      "          34       0.99      1.00      0.99       166\n",
      "          35       1.00      1.00      1.00       166\n",
      "          36       0.97      1.00      0.99       166\n",
      "          37       0.99      1.00      1.00       156\n",
      "          38       0.83      1.00      0.91       166\n",
      "          39       1.00      1.00      1.00       164\n",
      "          40       1.00      1.00      1.00       166\n",
      "          41       1.00      0.99      1.00       166\n",
      "          42       1.00      1.00      1.00       166\n",
      "          43       1.00      0.86      0.93       166\n",
      "          44       1.00      1.00      1.00       166\n",
      "          45       1.00      0.99      0.99       166\n",
      "          46       1.00      1.00      1.00       246\n",
      "          47       0.74      1.00      0.85       164\n",
      "          48       0.74      0.76      0.75       164\n",
      "          49       1.00      1.00      1.00       160\n",
      "          50       1.00      1.00      1.00       164\n",
      "          51       1.00      1.00      1.00       166\n",
      "          52       0.70      0.80      0.75       164\n",
      "          53       0.93      1.00      0.96       164\n",
      "          54       1.00      0.72      0.84       164\n",
      "          55       0.93      0.89      0.91       166\n",
      "          56       1.00      0.90      0.95       166\n",
      "          57       1.00      0.99      1.00       166\n",
      "          58       0.99      1.00      1.00       166\n",
      "          59       1.00      1.00      1.00       164\n",
      "          60       0.90      1.00      0.95       164\n",
      "          61       1.00      1.00      1.00       166\n",
      "          62       1.00      1.00      1.00       163\n",
      "          63       1.00      0.97      0.98       166\n",
      "          64       1.00      0.82      0.90       151\n",
      "          65       1.00      0.98      0.99       164\n",
      "          66       1.00      1.00      1.00       166\n",
      "          67       0.99      1.00      1.00       164\n",
      "          68       1.00      1.00      1.00       166\n",
      "          69       0.94      0.99      0.96       162\n",
      "          70       1.00      0.96      0.98       164\n",
      "          71       0.98      0.97      0.97       246\n",
      "          72       1.00      0.94      0.97       166\n",
      "          73       1.00      1.00      1.00       166\n",
      "          74       1.00      1.00      1.00       246\n",
      "          75       1.00      1.00      1.00       225\n",
      "          76       1.00      1.00      1.00       246\n",
      "          77       1.00      1.00      1.00       160\n",
      "          78       1.00      1.00      1.00       164\n",
      "          79       1.00      1.00      1.00       127\n",
      "          80       1.00      1.00      1.00       249\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     13877\n",
      "   macro avg       0.96      0.96      0.96     13877\n",
      "weighted avg       0.96      0.96      0.96     13877\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report\n",
    "print(classification_report(testLabels, predict_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
